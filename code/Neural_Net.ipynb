{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "b7b163cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "from sklearn.datasets import load_iris\n",
    "from sklearn.preprocessing import LabelBinarizer\n",
    "from sklearn.model_selection import train_test_split \n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "9b5844ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "save_folder = 'data_nan_mean'\n",
    "X_train = pd.read_csv('../data/' + save_folder + '/X_train.csv').values\n",
    "y_train = pd.read_csv('../data/' + save_folder + '/y_train.csv').values\n",
    "X_test = pd.read_csv('../data/' + save_folder + '/X_test.csv').values\n",
    "y_test = pd.read_csv('../data/' + save_folder + '/y_test.csv').values\n",
    "\n",
    "y_train = np.squeeze(y_train)\n",
    "n_values = np.max(y_train) + 1\n",
    "y_train = np.eye(n_values)[y_train]\n",
    "\n",
    "y_test = np.squeeze(y_test)\n",
    "n_values = np.max(y_test) + 1\n",
    "y_test = np.eye(n_values)[y_test]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "3229625b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_18\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_36 (Dense)            (None, 16)                160       \n",
      "                                                                 \n",
      " dense_37 (Dense)            (None, 16)                272       \n",
      "                                                                 \n",
      " output (Dense)              (None, 3)                 51        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 483\n",
      "Trainable params: 483\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "Epoch 1/300\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "in user code:\n\n    File \"c:\\Users\\Hiep\\anaconda3\\envs\\tf\\lib\\site-packages\\keras\\engine\\training.py\", line 1021, in train_function  *\n        return step_function(self, iterator)\n    File \"c:\\Users\\Hiep\\anaconda3\\envs\\tf\\lib\\site-packages\\keras\\engine\\training.py\", line 1010, in step_function  **\n        outputs = model.distribute_strategy.run(run_step, args=(data,))\n    File \"c:\\Users\\Hiep\\anaconda3\\envs\\tf\\lib\\site-packages\\keras\\engine\\training.py\", line 1000, in run_step  **\n        outputs = model.train_step(data)\n    File \"c:\\Users\\Hiep\\anaconda3\\envs\\tf\\lib\\site-packages\\keras\\engine\\training.py\", line 863, in train_step\n        self.optimizer.minimize(loss, self.trainable_variables, tape=tape)\n    File \"c:\\Users\\Hiep\\anaconda3\\envs\\tf\\lib\\site-packages\\keras\\optimizer_v2\\optimizer_v2.py\", line 532, in minimize\n        return self.apply_gradients(grads_and_vars, name=name)\n    File \"c:\\Users\\Hiep\\anaconda3\\envs\\tf\\lib\\site-packages\\keras\\optimizer_v2\\optimizer_v2.py\", line 668, in apply_gradients\n        grads_and_vars = self._aggregate_gradients(grads_and_vars)\n    File \"c:\\Users\\Hiep\\anaconda3\\envs\\tf\\lib\\site-packages\\keras\\optimizer_v2\\optimizer_v2.py\", line 484, in _aggregate_gradients\n        return self.gradient_aggregator(grads_and_vars)\n    File \"c:\\Users\\Hiep\\anaconda3\\envs\\tf\\lib\\site-packages\\keras\\optimizer_v2\\utils.py\", line 33, in all_reduce_sum_gradients\n        if tf.__internal__.distribute.strategy_supports_no_merge_call():\n\n    AttributeError: module 'tensorflow.compat.v2.__internal__.distribute' has no attribute 'strategy_supports_no_merge_call'\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32md:\\TTH\\app code\\Visual Studio\\python\\ML_HUST_PROJECT\\code\\Neural_Net.ipynb Cell 3'\u001b[0m in \u001b[0;36m<cell line: 11>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      <a href='vscode-notebook-cell:/d%3A/TTH/app%20code/Visual%20Studio/python/ML_HUST_PROJECT/code/Neural_Net.ipynb#ch0000002?line=6'>7</a>\u001b[0m model\u001b[39m.\u001b[39mcompile(loss\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39mcategorical_crossentropy\u001b[39m\u001b[39m'\u001b[39m, optimizer\u001b[39m=\u001b[39moptimizer,  metrics\u001b[39m=\u001b[39m[\u001b[39m'\u001b[39m\u001b[39macc\u001b[39m\u001b[39m'\u001b[39m])\n\u001b[0;32m      <a href='vscode-notebook-cell:/d%3A/TTH/app%20code/Visual%20Studio/python/ML_HUST_PROJECT/code/Neural_Net.ipynb#ch0000002?line=8'>9</a>\u001b[0m \u001b[39mprint\u001b[39m(model\u001b[39m.\u001b[39msummary())\n\u001b[1;32m---> <a href='vscode-notebook-cell:/d%3A/TTH/app%20code/Visual%20Studio/python/ML_HUST_PROJECT/code/Neural_Net.ipynb#ch0000002?line=10'>11</a>\u001b[0m model\u001b[39m.\u001b[39;49mfit(X_train, y_train, validation_data\u001b[39m=\u001b[39;49m(X_test, y_test), batch_size\u001b[39m=\u001b[39;49m\u001b[39m32\u001b[39;49m, epochs\u001b[39m=\u001b[39;49m\u001b[39m300\u001b[39;49m, verbose\u001b[39m=\u001b[39;49m\u001b[39m2\u001b[39;49m)\n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/TTH/app%20code/Visual%20Studio/python/ML_HUST_PROJECT/code/Neural_Net.ipynb#ch0000002?line=11'>12</a>\u001b[0m results \u001b[39m=\u001b[39m model\u001b[39m.\u001b[39mevaluate(X_test, y_test)\n",
      "File \u001b[1;32mc:\\Users\\Hiep\\anaconda3\\envs\\tf\\lib\\site-packages\\keras\\utils\\traceback_utils.py:67\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     <a href='file:///c%3A/Users/Hiep/anaconda3/envs/tf/lib/site-packages/keras/utils/traceback_utils.py?line=64'>65</a>\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:  \u001b[39m# pylint: disable=broad-except\u001b[39;00m\n\u001b[0;32m     <a href='file:///c%3A/Users/Hiep/anaconda3/envs/tf/lib/site-packages/keras/utils/traceback_utils.py?line=65'>66</a>\u001b[0m   filtered_tb \u001b[39m=\u001b[39m _process_traceback_frames(e\u001b[39m.\u001b[39m__traceback__)\n\u001b[1;32m---> <a href='file:///c%3A/Users/Hiep/anaconda3/envs/tf/lib/site-packages/keras/utils/traceback_utils.py?line=66'>67</a>\u001b[0m   \u001b[39mraise\u001b[39;00m e\u001b[39m.\u001b[39mwith_traceback(filtered_tb) \u001b[39mfrom\u001b[39;00m \u001b[39mNone\u001b[39m\n\u001b[0;32m     <a href='file:///c%3A/Users/Hiep/anaconda3/envs/tf/lib/site-packages/keras/utils/traceback_utils.py?line=67'>68</a>\u001b[0m \u001b[39mfinally\u001b[39;00m:\n\u001b[0;32m     <a href='file:///c%3A/Users/Hiep/anaconda3/envs/tf/lib/site-packages/keras/utils/traceback_utils.py?line=68'>69</a>\u001b[0m   \u001b[39mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[1;32mc:\\Users\\Hiep\\anaconda3\\envs\\tf\\lib\\site-packages\\tensorflow\\python\\framework\\func_graph.py:1143\u001b[0m, in \u001b[0;36mfunc_graph_from_py_func.<locals>.autograph_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m   <a href='file:///c%3A/Users/Hiep/anaconda3/envs/tf/lib/site-packages/tensorflow/python/framework/func_graph.py?line=1140'>1141</a>\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:  \u001b[39m# pylint:disable=broad-except\u001b[39;00m\n\u001b[0;32m   <a href='file:///c%3A/Users/Hiep/anaconda3/envs/tf/lib/site-packages/tensorflow/python/framework/func_graph.py?line=1141'>1142</a>\u001b[0m   \u001b[39mif\u001b[39;00m \u001b[39mhasattr\u001b[39m(e, \u001b[39m\"\u001b[39m\u001b[39mag_error_metadata\u001b[39m\u001b[39m\"\u001b[39m):\n\u001b[1;32m-> <a href='file:///c%3A/Users/Hiep/anaconda3/envs/tf/lib/site-packages/tensorflow/python/framework/func_graph.py?line=1142'>1143</a>\u001b[0m     \u001b[39mraise\u001b[39;00m e\u001b[39m.\u001b[39mag_error_metadata\u001b[39m.\u001b[39mto_exception(e)\n\u001b[0;32m   <a href='file:///c%3A/Users/Hiep/anaconda3/envs/tf/lib/site-packages/tensorflow/python/framework/func_graph.py?line=1143'>1144</a>\u001b[0m   \u001b[39melse\u001b[39;00m:\n\u001b[0;32m   <a href='file:///c%3A/Users/Hiep/anaconda3/envs/tf/lib/site-packages/tensorflow/python/framework/func_graph.py?line=1144'>1145</a>\u001b[0m     \u001b[39mraise\u001b[39;00m\n",
      "\u001b[1;31mAttributeError\u001b[0m: in user code:\n\n    File \"c:\\Users\\Hiep\\anaconda3\\envs\\tf\\lib\\site-packages\\keras\\engine\\training.py\", line 1021, in train_function  *\n        return step_function(self, iterator)\n    File \"c:\\Users\\Hiep\\anaconda3\\envs\\tf\\lib\\site-packages\\keras\\engine\\training.py\", line 1010, in step_function  **\n        outputs = model.distribute_strategy.run(run_step, args=(data,))\n    File \"c:\\Users\\Hiep\\anaconda3\\envs\\tf\\lib\\site-packages\\keras\\engine\\training.py\", line 1000, in run_step  **\n        outputs = model.train_step(data)\n    File \"c:\\Users\\Hiep\\anaconda3\\envs\\tf\\lib\\site-packages\\keras\\engine\\training.py\", line 863, in train_step\n        self.optimizer.minimize(loss, self.trainable_variables, tape=tape)\n    File \"c:\\Users\\Hiep\\anaconda3\\envs\\tf\\lib\\site-packages\\keras\\optimizer_v2\\optimizer_v2.py\", line 532, in minimize\n        return self.apply_gradients(grads_and_vars, name=name)\n    File \"c:\\Users\\Hiep\\anaconda3\\envs\\tf\\lib\\site-packages\\keras\\optimizer_v2\\optimizer_v2.py\", line 668, in apply_gradients\n        grads_and_vars = self._aggregate_gradients(grads_and_vars)\n    File \"c:\\Users\\Hiep\\anaconda3\\envs\\tf\\lib\\site-packages\\keras\\optimizer_v2\\optimizer_v2.py\", line 484, in _aggregate_gradients\n        return self.gradient_aggregator(grads_and_vars)\n    File \"c:\\Users\\Hiep\\anaconda3\\envs\\tf\\lib\\site-packages\\keras\\optimizer_v2\\utils.py\", line 33, in all_reduce_sum_gradients\n        if tf.__internal__.distribute.strategy_supports_no_merge_call():\n\n    AttributeError: module 'tensorflow.compat.v2.__internal__.distribute' has no attribute 'strategy_supports_no_merge_call'\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "\n",
    "model.add(Dense(16, input_shape=(9,), activation='relu'))\n",
    "model.add(Dense(16, activation='relu'))\n",
    "model.add(Dense(3, activation='softmax', name='output'))\n",
    "\n",
    "optimizer = Adam(lr=0.001)\n",
    "model.compile(optimizer, loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "print(model.summary())\n",
    "\n",
    "model.fit(X_train, y_train, verbose=2, batch_size=16, epochs=300)\n",
    "results = model.evaluate(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c294c1a",
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "\n",
    "model.add(Dense(16, input_shape=(9,), activation='relu'))\n",
    "model.add(Dense(16, activation='relu'))\n",
    "model.add(Dense(3, activation='softmax', name='output'))\n",
    "\n",
    "optimizer = Adam(learning_rate=0.001)\n",
    "model.compile(optimizer, loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "print(model.summary())\n",
    "\n",
    "model.fit(X_train, y_train, verbose=2, batch_size=16, epochs=300)\n",
    "results = model.evaluate(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f444311b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import ConfusionMatrixDisplay\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import matplotlib.pyplot as plt\n",
    "plt.style.use('default')\n",
    "\n",
    "y_predict = model.predict(X_test)\n",
    "y_predict = np.argmax(y_predict, axis=1)\n",
    "y_test_label = np.argmax(y_test, axis=1)\n",
    "\n",
    "labels = [\"Adelie\", \"Chinstrap\", \"Gentoo\"]\n",
    "\n",
    "cm = confusion_matrix(y_test_label, y_predict)\n",
    "\n",
    "disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=labels)\n",
    "\n",
    "disp.plot(cmap=plt.cm.Blues)\n",
    "plt.savefig('../pics/Neural_net/confusion_matrix')\n",
    "plt.savefig('../pics/Neural_net/confusion_matrix.pdf')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14287c3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "import seaborn as sns\n",
    "\n",
    "cm = confusion_matrix(y_test_label, y_predict)\n",
    "# Normalise\n",
    "cmn = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
    "fig, ax = plt.subplots(figsize=(10,10))\n",
    "sns.heatmap(cmn, annot=True, fmt='.2f', xticklabels=labels, yticklabels=labels)\n",
    "plt.ylabel('Actual')\n",
    "plt.xlabel('Predicted')\n",
    "plt.savefig('../pics/Neural_net/confusion_matrix_normalization')\n",
    "plt.savefig('../pics/Neural_net/confusion_matrix_normalization.pdf')\n",
    "plt.show(block=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1144083c",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "\n",
    "model.add(Dense(16, input_shape=(9,), activation='relu'))\n",
    "model.add(Dense(16, activation='relu'))\n",
    "model.add(Dense(3, activation='softmax', name='output'))\n",
    "\n",
    "optimizer = Adam(learning_rate=0.001)\n",
    "model.compile(optimizer, loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "print(model.summary())\n",
    "\n",
    "model.fit(X_train, y_train, verbose=2, batch_size=16, epochs=800)\n",
    "results = model.evaluate(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a3fd88b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import ConfusionMatrixDisplay\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import matplotlib.pyplot as plt\n",
    "plt.style.use('default')\n",
    "\n",
    "y_predict = model.predict(X_test)\n",
    "y_predict = np.argmax(y_predict, axis=1)\n",
    "y_test_label = np.argmax(y_test, axis=1)\n",
    "\n",
    "labels = [\"Adelie\", \"Chinstrap\", \"Gentoo\"]\n",
    "\n",
    "cm = confusion_matrix(y_test_label, y_predict)\n",
    "\n",
    "disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=labels)\n",
    "\n",
    "disp.plot(cmap=plt.cm.Blues)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d7274cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "\n",
    "model.add(Dense(16, input_shape=(9,), activation='relu'))\n",
    "model.add(Dense(16, activation='relu'))\n",
    "model.add(Dense(3, activation='softmax', name='output'))\n",
    "\n",
    "optimizer = Adam(learning_rate=0.001)\n",
    "model.compile(optimizer, loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "print(model.summary())\n",
    "\n",
    "model.fit(X_train, y_train, verbose=2, batch_size=16, epochs=1200)\n",
    "results = model.evaluate(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "378f3895",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import ConfusionMatrixDisplay\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import matplotlib.pyplot as plt\n",
    "plt.style.use('default')\n",
    "\n",
    "y_predict = model.predict(X_test)\n",
    "y_predict = np.argmax(y_predict, axis=1)\n",
    "y_test_label = np.argmax(y_test, axis=1)\n",
    "\n",
    "labels = [\"Adelie\", \"Chinstrap\", \"Gentoo\"]\n",
    "\n",
    "cm = confusion_matrix(y_test_label, y_predict)\n",
    "\n",
    "disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=labels)\n",
    "\n",
    "\n",
    "disp.plot(cmap=plt.cm.Blues)\n",
    "plt.savefig('../pics/Neural_net/confusion_matrix_1200_iteration')\n",
    "plt.savefig('../pics/Neural_net/confusion_matrix_1200_iteration.pdf')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31bddeda",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "import seaborn as sns\n",
    "\n",
    "cm = confusion_matrix(y_test_label, y_predict)\n",
    "# Normalise\n",
    "cmn = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
    "fig, ax = plt.subplots(figsize=(10,10))\n",
    "sns.heatmap(cmn, annot=True, fmt='.2f', xticklabels=labels, yticklabels=labels)\n",
    "plt.ylabel('Actual')\n",
    "plt.xlabel('Predicted')\n",
    "plt.savefig('../pics/Neural_net/confusion_matrix_normalization_1200_iteration')\n",
    "plt.savefig('../pics/Neural_net/confusion_matrix_normalization_1200_iteration.pdf')\n",
    "plt.show(block=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37b04d94",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "\n",
    "model.add(Dense(16, input_shape=(9,), activation='relu'))\n",
    "model.add(Dense(16, activation='relu'))\n",
    "model.add(Dense(3, activation='softmax', name='output'))\n",
    "\n",
    "optimizer = Adam(learning_rate=0.001)\n",
    "model.compile(optimizer, loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "print(model.summary())\n",
    "\n",
    "model.fit(X_train, y_train, verbose=2, batch_size=16, epochs=1500)\n",
    "results = model.evaluate(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0255e278",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "\n",
    "model.add(Dense(16, input_shape=(9,), activation='relu'))\n",
    "model.add(Dense(16, activation='relu'))\n",
    "model.add(Dense(3, activation='softmax', name='output'))\n",
    "\n",
    "optimizer = Adam(learning_rate=0.001)\n",
    "model.compile(optimizer, loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "print(model.summary())\n",
    "\n",
    "model.fit(X_train, y_train, verbose=2, batch_size=16, epochs=1800)\n",
    "results = model.evaluate(X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67e6c7d6",
   "metadata": {},
   "source": [
    "# Performance on data without island of experiments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0ee6eec",
   "metadata": {},
   "outputs": [],
   "source": [
    "save_folder = 'data_nan_mean_no_Island'\n",
    "X_train = pd.read_csv('../data/' + save_folder + '/X_train.csv').values\n",
    "y_train = pd.read_csv('../data/' + save_folder + '/y_train.csv').values\n",
    "X_test = pd.read_csv('../data/' + save_folder + '/X_test.csv').values\n",
    "y_test = pd.read_csv('../data/' + save_folder + '/y_test.csv').values\n",
    "\n",
    "y_train = np.squeeze(y_train)\n",
    "n_values = np.max(y_train) + 1\n",
    "y_train = np.eye(n_values)[y_train]\n",
    "\n",
    "y_test = np.squeeze(y_test)\n",
    "n_values = np.max(y_test) + 1\n",
    "y_test = np.eye(n_values)[y_test]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d9accdf",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "\n",
    "model.add(Dense(16, input_shape=(8,), activation='relu'))\n",
    "model.add(Dense(16, activation='relu'))\n",
    "model.add(Dense(3, activation='softmax', name='output'))\n",
    "\n",
    "optimizer = Adam(learning_rate=0.001)\n",
    "model.compile(optimizer, loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "print(model.summary())\n",
    "\n",
    "model.fit(X_train, y_train, verbose=2, batch_size=16, epochs=1000)\n",
    "results = model.evaluate(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "859bd927",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import ConfusionMatrixDisplay\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import matplotlib.pyplot as plt\n",
    "plt.style.use('default')\n",
    "\n",
    "y_predict = model.predict(X_test)\n",
    "y_predict = np.argmax(y_predict, axis=1)\n",
    "y_test_label = np.argmax(y_test, axis=1)\n",
    "\n",
    "labels = [\"Adelie\", \"Chinstrap\", \"Gentoo\"]\n",
    "\n",
    "cm = confusion_matrix(y_test_label, y_predict)\n",
    "\n",
    "disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=labels)\n",
    "\n",
    "\n",
    "disp.plot(cmap=plt.cm.Blues)\n",
    "plt.savefig('../pics/Neural_net/confusion_matrix_1000_iteration_no_Island')\n",
    "plt.savefig('../pics/Neural_net/confusion_matrix_1000_iteration_no_Island.pdf')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15a9dc88",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "import seaborn as sns\n",
    "\n",
    "cm = confusion_matrix(y_test_label, y_predict)\n",
    "# Normalise\n",
    "cmn = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
    "fig, ax = plt.subplots(figsize=(10,10))\n",
    "sns.heatmap(cmn, annot=True, fmt='.2f', xticklabels=labels, yticklabels=labels)\n",
    "plt.ylabel('Actual')\n",
    "plt.xlabel('Predicted')\n",
    "plt.savefig('../pics/Neural_net/confusion_matrix_normalization_1000_iteration_no_Island')\n",
    "plt.savefig('../pics/Neural_net/confusion_matrix_normalization_1000_iteration_no_Island.pdf')\n",
    "plt.show(block=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d4c9686",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "c2c62a62b6b3ac78c25ded2302f41219f58d7d9980c88ca5d8a7ac0a2fdc116b"
  },
  "kernelspec": {
   "display_name": "Python 3.9.6 ('tf')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
